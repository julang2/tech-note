
一个索引是否适合某个查询的"三星系统"（three-star system）：索引将相关的记录放到一起则获得一星；如果索引中的数据顺序和查找中的排列索引一致则获得二星；如果索引中的列包含了查询中需要的全部列则获得"三星"。

# 索引的常见模型

索引的出现是为了提高查询效率，但是实现索引的方式却有很多种，所以这里也就引入了索引模型的概念。可以用于提高读写效率的数据结构很多，这里我先给你介绍三种常见、也比较简单的数据结构，它们分别是哈希表、有序数组和搜索树。

## 哈希表

哈希表是一种以键-值（key-value）存储数据的结构，我们只要输入待查找的值即key，就可以找到其对应的值即Value。哈希的思路很简单，把值放在数组里，用一个哈希函数把key换算成一个确定的位置，然后把value放在数组的这个位置。

不可避免地，多个key值经过哈希函数的换算，会出现同一个值的情况。处理这种情况的一种方法是，拉出一个链表。

哈希表结构增加新的元素时速度会很快（O(1)），但是，因为不是有序的，所有做区间查询的速度是很慢的，必须全部扫描一遍。所以，哈希表适用于只有等值查询的场景。

## 有序数组

有序数组在等值查询和范围查询场景中的性能就都非常优秀。使用二分法进行查找，时间复杂度是O(log(N))。但是，插入新元素时必须移动后面所有的元素，成本太高。

有序数组索引只适用于静态存储引擎。

## 搜索树

二叉搜索树的特点是：每个节点的左儿子小于父节点，父节点又小于右儿子。查找某个元素的时间复杂度是O(log(N))。当然为了维持O(log(N))的查询复杂度，你需要保持这个树是平衡二叉树。为了做这个保证，更新的时间复杂度也是O(log(N))。

在多叉树结构中，二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。

磁盘的读取数据块的数量和树的高度有关系。假如一棵100万节点的平衡二叉树，树高20，一次查询可能需要访问20个数据块。在机械硬盘时代，从磁盘随机读取一个数据块需要`10ms`左右的寻址时间。对于一个100万行的表，如果使用二叉树来存储，单独访问一个行可能需要20个10ms的时间，可真够慢的。

为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N叉”树。这里，“N叉”树中的“N”取决于数据块的大小。

树根的数据块总是在内存中的，树的第二层次也有很大概率在内存中，那么访问磁盘的平均次数就更少了。

N叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。

二叉树的变种:BTREE(又写成B-tree),B+tree和B*tree.

B-tree即balance-tree:平衡树:假设1个节点的子节点是5个,平衡树是必须上层节点都满了,才可加到下层.这样树的深度就得到了控制.B-tree除了在叶子节点保存数据,在非叶子节点也保存数据.

B+tree:所有数据都存储在叶子节点,非叶子节点不存储数据.且叶子节点间构成了双向链表。Mysql用的方法是B+tree.

b+tree的插入必须要保证插入后，叶子节点的数据依然有序。而且不管怎么变化，根节点到叶子节点的深度始终是相同的。

B*tree:也只在叶子节点存储数据并构成双向指针,但在非叶子节点有双向指针。

# InnoDB的索引模型

在InnoDB中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。InnoDB使用了B+树索引模型，所以数据都是存储在B+树中的。

根据叶子节点的内容，索引类型分为主键索引和非主键索引（普通索引）。

- 主键索引的叶子节点存的是整行数据。在InnoDB里，主键索引也被称为聚簇索引（clustered index）。查询语句只需要搜索主键这棵B+树。

- 非主键索引的叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为二级索引（secondary index）。需先搜索非主键这棵索引树，带到主键的值，再到主键索引树搜索一次，获取整行记录，这个过程称为`回表`。

基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。

## 索引维护

B+树为了维护索引有序性，在插入新值的时候需要做必要的维护。

如果插入新的行ID值为700，则只需要在R5的记录后面插入一个新记录。如果新插入的ID值为400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。

而更糟的情况是，如果R5所在的数据页已经满了，根据B+树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为`页分裂`。在这种情况下，性能自然会受影响。

除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约50%。

当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。

**自增主键**每次插入一条新记录，都是追加操作，保证有序插入，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。从存储空间的角度来看，由于每个非主键索引的叶子节点上都是主键的值，如果用整型做主键，则只要4个字节，长整型（bigint）则是8个字节。显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。

业务字段做主键的需求，典型的KV场景：

- 只有一个索引，由于没有其他索引，也就不用考虑其他索引的叶子节点大小的问题。

- 该索引必须是唯一索引。

## 索引规则

### 覆盖索引

如果某个查询的结果可以直接由该索引提供（包括索引键和值），不需要回表查询，则该索引已经“覆盖了”我们的查询需求，我们称为**覆盖索引**。

由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。

索引字段的维护总是有代价的。因此，在建立冗余索引来支持覆盖索引时就需要权衡考虑了。

### 最左前缀原则-联合索引

B+树这种索引结构，可以利用索引的“最左前缀”，来定位记录。

这个最左前缀可以是联合索引的最左N个字段，也可以是**字符串索引**的最左M个字符。

在建立联合索引的时候，如何安排索引内的字段顺序:

- 第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。

- 考虑空间，如果a字段比b字段大，建议创建一个(a,b)的联合索引和一个(b)的单字段索引。

### 索引下推（index condition pushdown）

在MySQL 5.6之前，只能从ID3开始一个个回表。到主键索引上找出数据行，再对比字段值。

而MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。

## 普通索引和唯一索引

InnoDB的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在InnoDB中，每个数据页的大小默认是16KB（对于整型字段，一个数据页可以放近千个key）。

### 查询过程

在查询过程中，唯一索引和普通索引的性能差距微乎其微。

### 更新过程

当需要更新一个数据页时，如果数据页在内存中（InnoDB buffer pool）就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB会将这些更新操作缓存在`change buffer`中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行`change buffer`中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。

`change buffer`是可以持久化的数据，在内存中有拷贝，也会写入到磁盘上。

将`change buffer`中的操作应用到原数据页，得到最新结果的过程称为`merge`。除了访问这个数据页会触发`merge`外，系统有后台线程会定期`merge`。在数据库正常关闭（shutdown）的过程中，也会执行`merge`操作。

将数据更新操作记录在`change buffer`，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用`buffer pool`的，所以这种方式还能避免占用内存，提高内存利用率。

对于唯一索引来说，所有的更新操作都要判断这个操作是否违反唯一性约束，必须将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用`change buffer`了。

实际上也只有普通索引可以使用。

`change buffer`用的是`buffer pool`里的内存，因此不能无限增大。`change buffer`的大小，可以通过参数`innodb_change_buffer_max_size`来动态设置。这个参数设置为50的时候，表示`change buffer`的大小最多只能占用`buffer pool`的50%。

将数据从磁盘读入内存涉及**随机IO**的访问，是数据库里面成本最高的操作之一。`change buffer`因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。

#### change buffer的使用场景

因为`merge`的时候是真正进行数据更新的时刻，而`change buffer`的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做`merge`之前，`change buffer`记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。

因此，对于**写多读少**的业务来说，页面在写完以后马上被访问到的概率比较小，此时`change buffer`的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。

反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在`change buffer`，但之后由于马上要访问这个数据页，会立即触发merge过程。这样随机访问IO的次数不会减少，反而增加了`change buffer`的维护代价。所以，对于这种业务模式来说，`change buffer`反而起到了副作用。

- 首先，业务正确性优先。。如果业务不能保证，或者业务就是要求数据库来做约束，那么没得选，必须创建唯一索引。

- 然后，在一些“归档库”的场景，如果已经确保归档数据没有唯一键冲突，要提供归档效率，可以考虑把表里面的唯一索引改成普通索引。

在实际使用中，你会发现，普通索引和`change buffer`的配合使用，对于数据量大的表的更新优化还是很明显的。

特别地，在使用机械硬盘时，`change buffer`这个机制的收效是非常显著的。所以，当你有一个类似“历史数据”的库，并且出于成本考虑用的是机械硬盘时，那你应该特别关注这些表里的索引，尽量使用普通索引，然后把`change buffer`尽量开大，以确保这个“历史数据”表的数据写入速度。

#### change buffer和redo log

如果要简单地对比这两个机制在提升更新性能上的收益的话，`redo log`主要节省的是随机写磁盘的IO消耗（转成顺序写），而`change buffer`主要节省的则是随机读磁盘的IO消耗。

`change buffer`一开始是写内存的，那么如果这个时候机器掉电重启，会不会导致change buffer丢失呢？
    不会丢失，虽然是只更新内存，但是在事务提交的时候，我们把`change buffer`的操作也记录到redo log里了，所以崩溃恢复的时候，`change buffer`也能找回来。



